{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Open Set Emotion Recognition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Library Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import librosa\n",
    "import re\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Creation"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MELD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class MELDDataset(Dataset):\n",
    "    def __init__(self, meld_dir, split, transform=None):\n",
    "        self.meld_dir = meld_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.audio_files = self.load_audio_files()\n",
    "        self.dialogues = self.load_dialogues()\n",
    "\n",
    "    def load_audio_files(self):\n",
    "        audio_dir = os.path.join(self.meld_dir, f'{self.split}_audio')\n",
    "        audio_files = os.listdir(audio_dir)\n",
    "        return audio_files\n",
    "\n",
    "    def load_dialogues(self):\n",
    "        dialogue_file = os.path.join(self.meld_dir, f'{self.split}_sent_emo.csv')\n",
    "        dialogues = pd.read_csv(dialogue_file)\n",
    "        return dialogues\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dialogues)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dialogues.iloc[idx]\n",
    "        text = row['Utterance']\n",
    "        audio_dir = os.path.join(self.meld_dir, f'{self.split}_audio')\n",
    "        audio_data = librosa.load(os.path.join(audio_dir, f'dia{row[\"Dialogue_ID\"]}_utt{row[\"Utterance_ID\"]}.wav'))\n",
    "        label = row['Emotion']\n",
    "        if self.transform:\n",
    "            audio_data[0] = self.transform(audio_data[0])\n",
    "        return text, audio_data, label\n",
    "\n",
    "train_meld = MELDDataset(\"../MELD_Dataset\", \"train\")\n",
    "test_meld = MELDDataset(\"../MELD_Dataset\", \"test\")\n",
    "dev_meld = MELDDataset(\"../MELD_Dataset\", \"dev\")\n",
    "\n",
    "# concat all 3 datasets into 1 dataset\n",
    "meld_dataset = train_meld + test_meld + dev_meld"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "('also I was the point person on my company\\x92s transition from the KL-5 to GR-6 system.',\n (array([-0.00198962, -0.02142129, -0.02587057, ..., -0.06124197,\n         -0.06868309, -0.04373461], dtype=float32),\n  22050),\n 'neutral')"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meld_dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### IEMOCAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY:\n",
      "\n",
      "Problematic Transcription Line: 152\n",
      "Unavailable Label for an utterance: 48\n"
     ]
    }
   ],
   "source": [
    "class IemocapDataset(Dataset):\n",
    "    def __init__(self, iemocap_dataset_full_path, transform=None):\n",
    "        self.IEMOCAP_MAIN_FOLDER = os.path.join(iemocap_dataset_full_path, \"IEMOCAP_full_release\")\n",
    "        self.TRANSCRIPTION_FOLDER = os.path.join(\"dialog\", \"transcriptions\")\n",
    "        self.AUDIO_FOLDER = os.path.join(\"sentences\", \"wav\")\n",
    "        self.CATEGORICAL_LABELS_PATH = os.path.join(\"dialog\", \"EmoEvaluation\", \"Categorical\")\n",
    "        self.transform = transform\n",
    "\n",
    "        self.errors = defaultdict(int)\n",
    "        self.dataset = self.create_dataset()\n",
    "        self.print_summary()\n",
    "\n",
    "    def get_evaluator_filenames_with_video_file_prefix(self, input_list, prefix_value):\n",
    "        regex_pattern = re.compile(f'^{re.escape(prefix_value)}.*\\.txt$')\n",
    "        matching_strings = [s for s in input_list if regex_pattern.match(s)]\n",
    "        return matching_strings\n",
    "\n",
    "    def get_utterance_to_evaluationCounter_mapping_from_evaluation_files(self, evaluation_files):\n",
    "        utterance_to_all_evaluations = {}\n",
    "\n",
    "        for evaluation_file in evaluation_files:\n",
    "            utterance_to_evaluationList = {}\n",
    "            with open(evaluation_file,'r') as f:\n",
    "                contents = f.read()\n",
    "                utterance_evaluations = contents.split(\"\\n\")\n",
    "                for evaluation in utterance_evaluations:\n",
    "                    evaluation = evaluation.strip()\n",
    "                    if len(evaluation) == 0:\n",
    "                        continue\n",
    "                    matches = re.findall(r':[^;]+;', evaluation)\n",
    "                    matches = [match[1:-1] for match in matches]\n",
    "                    utterance_to_evaluationList[evaluation.split()[0]] = matches\n",
    "\n",
    "            # Combine lists from dict1\n",
    "            for key, value_list in utterance_to_evaluationList.items():\n",
    "                utterance_to_all_evaluations[key] = utterance_to_all_evaluations.get(key, []) + value_list\n",
    "\n",
    "        utterance_to_evaluationsCounter = {k:Counter(v).most_common(1)[0][0] for k,v in utterance_to_all_evaluations.items()}\n",
    "        return utterance_to_evaluationsCounter\n",
    "\n",
    "    def create_dataset(self):\n",
    "        dataset = []\n",
    "        for session_num in range(1,6):\n",
    "            for transcription_filename in os.listdir(os.path.join(self.IEMOCAP_MAIN_FOLDER,f\"Session{session_num}\", self.TRANSCRIPTION_FOLDER)):\n",
    "                if transcription_filename[0] != \".\":\n",
    "                    filename_without_extension = transcription_filename.split(\".\")[0]\n",
    "\n",
    "                    categorical_labels_folder_full_path = os.path.join(self.IEMOCAP_MAIN_FOLDER, f\"Session{session_num}\", self.CATEGORICAL_LABELS_PATH)\n",
    "                    evaluation_filenames = self.get_evaluator_filenames_with_video_file_prefix(os.listdir(categorical_labels_folder_full_path), filename_without_extension)\n",
    "                    evaluation_files_full_paths_for_this_file = [os.path.join(self.IEMOCAP_MAIN_FOLDER, f\"Session{session_num}\", self.CATEGORICAL_LABELS_PATH, f) for f in evaluation_filenames]\n",
    "                    evaluations_per_utterance = self.get_utterance_to_evaluationCounter_mapping_from_evaluation_files(evaluation_files_full_paths_for_this_file)\n",
    "\n",
    "                    transcription_file_full_path = os.path.join(self.IEMOCAP_MAIN_FOLDER, f\"Session{session_num}\", self.TRANSCRIPTION_FOLDER, transcription_filename)\n",
    "                    with open(transcription_file_full_path,'r') as f:\n",
    "                        contents = f.read()\n",
    "                        lines = contents.split(\"\\n\")\n",
    "\n",
    "                        # Iterate through utterances where every utterance looks like:\n",
    "                        # Ses01F_impro01_F000 [006.2901-008.2357]: Excuse me.\n",
    "                        for line in lines:\n",
    "\n",
    "                            # Remove extra spaces and check if the line is not an empty link (usually at EOF)\n",
    "                            line = line.strip()\n",
    "                            if(len(line)==0):\n",
    "                                break\n",
    "\n",
    "                            # Remove idx of first space, ], -\n",
    "                            try:\n",
    "                                space_idx = line.index(\" \")\n",
    "                                timestampEndBracket_idx = line.index(\"]\")\n",
    "                                timestampHyphen_idx = line.index(\"-\")\n",
    "                            except:\n",
    "                                self.errors[\"Problematic Transcription Line\"]+=1\n",
    "                                continue\n",
    "                            else:\n",
    "                                audio_filename = line[:space_idx]        # output audio file name = utterance name\n",
    "                                text = line[timestampEndBracket_idx+3:]         # the transcription of the utterance\n",
    "                                evaluation = evaluations_per_utterance.get(audio_filename,\"KEY_ERROR\")\n",
    "                                if(evaluation==\"KEY_ERROR\"):\n",
    "                                    self.errors[\"Unavailable Label for an utterance\"]+=1\n",
    "\n",
    "                                utterance_audios_per_video_folder = audio_filename[:line.rindex('_')]       # Only need Ses01F_impro01 from Ses01F_impro01_F000\n",
    "                                audio_file_full_path = os.path.join(self.IEMOCAP_MAIN_FOLDER, f\"Session{session_num}\", self.AUDIO_FOLDER, utterance_audios_per_video_folder, audio_filename+\".wav\")         # name of the video file\n",
    "\n",
    "                                if evaluation!=\"KEY_ERROR\" and os.path.isfile(audio_file_full_path)==True:\n",
    "                                    dataset.append((text,audio_file_full_path,evaluation))\n",
    "        return dataset\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(\"SUMMARY:\\n\")\n",
    "        for k,v in self.errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text, audio, label = self.dataset[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            audio[0] = self.transform(audio[0])\n",
    "        return text, librosa.load(audio), label\n",
    "\n",
    "iemocap_dataset = IemocapDataset(\"../IEMOCAP_Dataset\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "('Excuse me.',\n (array([-0.00476289, -0.0055054 , -0.00418305, ..., -0.00345229,\n         -0.0044057 , -0.00205744], dtype=float32), 22050),\n 'Neutral state')"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iemocap_dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([-1.97807834e-01, -3.21971893e-01,  1.74944237e-01,  5.88698089e-02,\n       -8.24544728e-02, -9.44081992e-02, -2.41122276e-01,  4.06191707e-01,\n       -4.01808284e-02, -4.22902219e-02, -2.42862441e-02,  4.39610481e-02,\n        4.06122029e-01, -6.70870207e-03,  2.19272390e-01, -1.17840350e-01,\n        5.50280735e-02, -9.10694078e-02,  4.62006390e-01, -6.63721561e-03,\n       -2.88291685e-02,  2.31405236e-02,  1.55743495e-01,  5.23088813e-01,\n       -7.16724917e-02,  1.73188880e-01, -1.97734818e-01,  2.80617148e-01,\n       -2.52348661e-01,  2.27498002e-02,  2.16145024e-01, -1.03119127e-02,\n       -1.54864728e-01,  1.01391830e-01, -1.45695031e-01, -4.98875342e-02,\n       -1.62815645e-01,  7.69490898e-02, -5.53310633e-01,  7.87323341e-04,\n       -6.94538474e-01, -3.27924848e-01,  3.03773314e-01, -4.50806618e-02,\n       -3.67972553e-01,  1.69997901e-01,  9.03725624e-02, -6.69086426e-02,\n        4.09864068e-01, -2.58970767e-01, -2.32696936e-01, -4.69171628e-02,\n       -1.00126803e-01, -2.76727080e-01, -1.84954688e-01,  2.87459493e-01,\n        1.37695253e-01, -3.52508068e-01, -2.19019443e-01,  5.63413836e-02,\n       -6.24207407e-02, -2.25757629e-01,  3.06912482e-01, -1.35784656e-01,\n        3.23946588e-02, -1.96013421e-01,  2.47428656e-01,  5.49569845e-01,\n       -2.96380013e-01,  2.96305090e-01, -2.30058059e-01, -8.93797539e-03,\n        1.51722476e-01, -2.35742360e-01,  2.10511178e-01, -9.95195471e-03,\n        8.45624879e-03,  2.98192166e-02,  8.87270719e-02,  2.71937430e-01,\n       -1.13222465e-01,  3.30437869e-01, -2.77976096e-01,  4.70478414e-03,\n        3.18083093e-02,  2.90950358e-01, -2.89038680e-02,  1.79917198e-02,\n        1.90769732e-01,  3.20310205e-01, -2.76594579e-01,  1.44765191e-02,\n        1.06536523e-01,  6.55194968e-02,  2.72553355e-01, -4.72644955e-01,\n        4.83128503e-02, -8.10138509e-02,  6.91631138e-02, -1.23739041e-01,\n       -1.12901591e-01, -3.25597644e-01,  1.12739719e-01,  3.78145799e-02,\n       -1.56229526e-01, -1.29778057e-01,  2.31599003e-01,  1.57854371e-02,\n       -5.32483399e-01,  3.66934597e-01,  5.73982559e-02,  1.27840936e-01,\n       -3.61932337e-01, -6.78874403e-02, -1.85107291e-01,  3.28153878e-01,\n       -4.12919581e-01, -2.86297977e-01,  3.24304819e-01,  4.00408447e-01,\n        2.09841311e-01,  4.90950763e-01, -3.64894241e-01,  2.05946296e-01,\n       -2.16389969e-01, -4.36176322e-02,  2.40922660e-01,  9.95629057e-02,\n       -2.82252371e-01, -1.90296084e-01,  4.67096597e-01,  4.41928238e-01,\n        3.68491828e-01,  2.12646782e-01,  1.86679035e-01,  6.29506409e-02,\n        4.86312151e-01, -1.62008256e-02,  7.68303405e-03, -7.12313205e-02,\n       -1.07191533e-01, -2.14097261e-01,  3.21544111e-01, -2.34678864e-01,\n        1.04202904e-01, -2.72167884e-02,  1.32692456e-02,  1.06257103e-01,\n       -2.68425465e-01, -2.55449980e-01, -2.26665050e-01,  2.28976488e-01,\n       -2.62164503e-01, -8.59323964e-02, -4.26124558e-02, -5.05881459e-02,\n       -4.91398796e-02,  5.48495539e-02, -4.98603731e-02,  1.82679236e-01,\n        1.10341273e-01,  8.43904167e-02, -3.99211496e-01,  3.02458435e-01,\n       -1.54302508e-01,  2.22220644e-01, -1.65259764e-01,  9.82924700e-02,\n        1.85324878e-01, -1.33609802e-01,  6.52991608e-03, -1.17849693e-01,\n        1.31290173e-02, -1.80526406e-01, -1.79252684e-01,  4.81035747e-02,\n        1.11805752e-01, -3.34345438e-02, -1.59934223e-01,  1.26376420e-01,\n       -1.98564887e-01, -8.04332346e-02, -1.03952475e-01, -3.49928379e-01,\n        1.84266433e-01, -2.43896127e-01,  2.03461632e-01, -2.04478621e-01,\n        2.36100018e-01, -4.44405079e-02, -5.54244854e-02, -3.48154038e-01,\n        2.41304770e-01,  1.23057976e-01,  4.24033999e-02, -4.02807921e-01,\n       -3.81247550e-02, -2.60350883e-01, -5.01508079e-03, -1.10402377e-02,\n        1.42083913e-01,  6.79707825e-02,  2.08414514e-02, -1.84039533e-01,\n        8.36219266e-02, -8.64431560e-02,  9.35570449e-02,  5.35589866e-02,\n        1.08692627e-02,  3.20045054e-01, -3.74604225e-01,  4.55374122e-01,\n       -1.13131657e-01,  2.19899446e-01,  2.92751849e-01, -4.30763960e-02,\n       -3.54548723e-01, -2.18417823e-01,  1.37245059e-01, -2.15582222e-01,\n       -1.55330926e-01, -2.87440091e-01, -2.96061516e-01, -1.99019406e-02,\n       -1.62910312e-01,  2.73688823e-01,  6.32692575e-02, -1.19355526e-02,\n        4.48231727e-01,  6.00570560e-01, -3.67852569e-01, -7.35737026e-01,\n       -1.12040207e-01, -3.50656897e-01, -3.85428928e-02,  2.29819156e-02,\n       -1.87594593e-01, -3.58594775e-01, -9.58480313e-02,  9.27137956e-02,\n       -2.67871290e-01,  2.04643726e-01,  7.76365399e-04,  8.44214633e-02,\n        4.25384864e-02,  5.03355749e-02,  2.14775592e-01, -2.52461344e-01,\n        5.55861443e-02, -4.55221310e-02, -4.54750180e-01,  3.39988135e-02,\n        3.72178137e-01, -1.88516855e-01,  2.16230810e-01, -2.25375041e-01,\n       -1.56535208e-01,  3.64905179e-01,  3.26876864e-02, -1.30121231e-01,\n        4.49155480e-01,  1.07749343e-01, -1.13984853e-01, -1.35361403e-01,\n       -3.80109623e-02,  1.30640879e-01,  1.42957062e-01, -7.25717247e-02,\n        4.72024158e-02, -1.81442704e-02, -2.28653342e-01, -5.01426935e-01,\n       -5.90280220e-02,  4.11313474e-01, -1.42418459e-01, -6.35609865e-01,\n        5.58436178e-02,  2.01482132e-01, -1.48724526e-01, -1.78401500e-01,\n       -1.29928604e-01,  4.25754599e-02, -5.16448498e-01,  2.06934765e-01,\n       -1.14977300e-01,  1.86243117e-01, -1.01753473e-01, -5.19921422e-01,\n       -2.17665732e-03, -1.58865094e-01,  1.80065438e-01,  3.87417898e-02,\n       -1.52238041e-01,  2.07551681e-02,  2.21334100e-01,  1.28184542e-01,\n       -1.12859860e-01, -1.51434988e-01,  2.56626010e-01, -4.18029763e-02,\n       -3.68003845e-01,  2.12200969e-01,  2.92723238e-01, -2.91724682e-01,\n        3.67405415e-01, -1.39131799e-01, -1.80531800e-01, -9.81383845e-02,\n       -1.37425938e+01,  9.91907865e-02, -3.80302429e-01, -1.40854880e-01,\n        2.32984692e-01,  2.08175391e-01, -1.96891308e-01,  2.41449863e-01,\n       -1.93628166e-02, -1.32787034e-01, -2.46108562e-01,  2.20083088e-01,\n        8.66733938e-02, -3.70601386e-01, -2.37352923e-02, -5.28586991e-02,\n        3.09809893e-02, -2.96504736e-01, -8.28913376e-02,  1.88507110e-01,\n        1.57889590e-01, -3.82464707e-01,  2.11215705e-01,  2.56618485e-03,\n       -6.38611913e-02, -1.46081299e-01, -4.92023587e-01, -4.15141396e-02,\n       -3.65436792e-01, -1.87565863e-01,  1.05634779e-02, -1.61731765e-01,\n       -2.37319827e-01,  3.64559829e-01,  2.37120479e-01, -5.24690270e-01,\n       -6.52489066e-02, -1.68065444e-01,  5.67613952e-02,  1.03427589e-01,\n        3.73454839e-01,  4.43493351e-02,  1.18004248e-01, -3.78474221e-03,\n        2.58010507e-01, -1.08123071e-01,  1.24484003e-01,  1.27108693e-02,\n        5.71112782e-02,  3.80192310e-01,  4.27827775e-01, -6.50243163e-02,\n       -1.90439135e-01, -1.52000129e-01,  2.34546602e-01, -3.24088812e-01,\n        4.43364792e-02,  2.64942169e-01,  5.77208120e-03,  2.21236721e-02,\n        3.15560490e-01, -3.85514945e-01, -1.98238149e-01, -1.55428246e-01,\n       -1.85092181e-01,  7.40467831e-02, -1.96472421e-01, -3.97926390e-01,\n        1.70457393e-01, -2.07194433e-01,  1.64637566e-01, -1.08107358e-01,\n       -8.50000381e-02, -2.06623626e+00, -5.25143594e-02, -3.82405162e-01,\n        7.52243176e-02,  3.68574187e-02,  2.23024368e-01, -1.71773165e-01,\n       -1.70509398e-01, -2.11455286e-01,  2.86528558e-01,  6.23872876e-02,\n       -1.19279392e-01,  8.35568830e-02,  5.26256859e-02,  2.50036288e-02,\n        1.19400285e-02, -1.40132785e-01,  8.63043144e-02,  1.73953176e-01,\n        2.87508070e-01,  1.32599622e-02, -4.19215597e-02, -4.05727178e-01,\n        3.12613010e-01, -2.34801441e-01, -8.20532590e-02, -2.74997316e-02,\n       -1.07499644e-01,  1.77353039e-01, -5.51660806e-02,  1.02157235e-01,\n       -2.32538685e-01, -1.40280863e-02, -2.01970086e-01, -2.36715585e-01,\n        1.49639577e-01,  5.18686213e-02,  1.59462452e-01, -3.81956585e-02,\n        2.83793449e-01, -1.65352821e-01,  1.15092501e-01,  1.06912449e-01,\n       -5.01087457e-02,  1.49556309e-01,  5.24325520e-02, -2.69663095e-01,\n       -4.81273651e-01,  2.72418767e-01, -2.10627943e-01, -8.39649811e-02,\n       -8.24346244e-02,  1.33176353e-02, -3.06060255e-01,  3.07143629e-02,\n       -1.04292855e-01, -8.10647681e-02, -8.23582336e-03,  2.85866678e-01,\n       -3.05088371e-01, -1.01225443e-01, -9.99864563e-03, -1.25554785e-01,\n        1.98240709e-02,  4.80307490e-01, -7.57214334e-03, -8.84517655e-03,\n        3.11274171e-01,  3.74100834e-01,  1.52274191e-01, -3.97569716e-01,\n       -1.73378870e-01, -2.03387558e-01, -3.09992522e-01,  2.39323527e-01,\n        3.18738937e-01, -6.29922077e-02, -1.06089324e-01, -6.95088655e-02,\n       -9.20132846e-02,  3.89553979e-02, -2.35141814e-01,  2.13148460e-01,\n        4.17515635e-01, -2.37819359e-01,  4.77912277e-02, -8.20348188e-02,\n        5.35486162e-01, -6.60414398e-02,  1.62525654e-01, -2.86971200e-02,\n        2.93390393e-01,  3.76559258e-01,  1.89017504e-02, -6.96258396e-02,\n        2.33528078e-01, -1.60941854e-01, -5.13545573e-02, -1.18615896e-01,\n       -1.41367748e-01, -1.61925256e-01, -1.97419990e-02,  4.80473787e-02,\n        1.04829557e-02, -3.73697996e-01, -1.06892087e-01,  1.23748481e-01,\n        1.03972247e-03,  8.36391002e-02, -1.44513220e-01,  3.65464352e-02,\n        3.27637754e-02, -1.45634234e-01, -2.99838722e-01, -2.56856740e-01,\n       -1.63713649e-01,  1.41219914e-01,  4.45673689e-02, -8.28291327e-02,\n       -3.23757321e-01, -4.53271344e-02, -9.00504440e-02, -1.96668833e-01,\n       -2.20084377e-02,  5.85029274e-02, -1.46618575e-01, -2.97977924e-01,\n       -5.84494352e-01,  1.60832226e-01,  1.74840644e-01,  1.27987534e-01,\n        1.05164498e-01,  1.73912764e-01,  2.85458416e-01,  4.30953175e-01,\n        2.66578197e-01, -3.70121226e-02,  2.34848842e-01, -3.79060566e-01,\n       -2.53931805e-02,  1.45946607e-01,  2.04425693e-01,  8.48918185e-02,\n       -5.27580529e-02,  3.66526037e-01, -4.09598619e-01,  1.58741936e-01,\n       -1.75880834e-01, -1.90321758e-01,  4.17317331e-01, -2.51816273e-01,\n       -1.22450650e-01,  1.59586340e-01, -9.85329822e-02,  1.90852195e-01,\n       -3.42378825e-01,  7.69883301e-03, -1.28619343e-01, -5.99383891e-01,\n        3.19528699e-01,  2.37277031e-01,  3.23647857e-02, -8.56554955e-02,\n       -9.77605358e-02,  3.73880297e-01,  2.76709616e-01, -8.48626122e-02,\n        2.46801630e-01, -2.74729729e-01, -1.70588896e-01, -9.17890668e-02,\n        1.35981768e-01, -8.03629637e-01,  8.70643184e-02,  7.20131546e-02,\n       -2.38966972e-01,  2.36088634e-01, -7.97966570e-02, -2.72379726e-01,\n       -5.52695468e-02, -1.00093246e-01,  2.45211467e-01, -8.14832568e-01,\n       -3.26065361e-01, -2.20261663e-01,  1.06638923e-01, -4.64584455e-02,\n       -2.76748478e-01,  3.34441125e-01, -3.45737755e-01, -3.73587608e-02,\n       -6.20521531e-02,  7.78419748e-02, -5.05664825e-01,  1.28715396e-01,\n       -3.18798199e-02, -1.72761112e-01,  5.76364696e-02, -2.80438691e-01,\n        2.59306729e-01, -8.80299807e-02,  1.83987468e-01, -3.88808429e-01,\n       -2.91384459e-01,  7.52539001e-03,  1.78905293e-01, -1.52859747e-01,\n       -6.15886673e-02,  3.61325979e-01,  2.95123696e-01, -2.70038247e-01,\n       -2.38272063e-02, -9.02126729e-03, -2.04941686e-02, -1.48481773e-02,\n       -2.41291672e-01,  2.13165924e-01, -1.31380260e-01,  4.65133429e-01,\n       -1.28719807e-01,  3.45234632e-01, -2.12029949e-01,  1.83524936e-03,\n        1.17519610e-01, -3.80413756e-02, -2.28262901e-01,  2.40457863e-01,\n        2.93472484e-02,  6.81013986e-03,  2.17980146e-01,  2.59793013e-01,\n        6.54908177e-03, -6.61911368e-02,  5.56515306e-02,  7.01165348e-02,\n        1.09579697e-01,  2.43616819e-01, -1.10472646e-02, -3.49798411e-01,\n        1.78573653e-01,  2.46722147e-01, -2.65761465e-01, -4.59330857e-01,\n        2.17539892e-01,  4.75475341e-02, -1.21499315e-01, -3.72392982e-02,\n        2.15974540e-01, -6.68412000e-02,  2.27000982e-01, -2.51294613e-01,\n        6.80882633e-02,  1.90700203e-01,  3.55181796e-03, -5.31911850e-04,\n       -3.52421820e-01, -1.23576000e-02,  7.60637820e-02,  2.57901013e-01,\n        3.40666205e-01, -8.31837505e-02,  6.24953955e-03,  1.97762832e-01,\n        2.01484531e-01, -1.61890835e-01,  6.85039088e-02,  3.25952262e-01,\n       -2.56426930e-01,  1.87858015e-01, -3.27280402e-01,  9.25229341e-02,\n        3.99766147e-01,  2.45681420e-01, -1.92596585e-01,  1.80022329e-01,\n        4.71735597e-01,  8.05127025e-02, -1.84157267e-01, -1.63825616e-01,\n        1.98061645e-01, -1.80091172e-01,  1.35512009e-01,  1.47957101e-01,\n       -7.13268518e-02,  2.83478703e-02,  2.60906547e-01,  6.42577350e-01,\n        4.02892888e-01, -1.93096906e-01,  3.19647402e-01, -2.29444638e-01,\n       -3.63672256e-01,  2.30159163e-01,  4.17354167e-01, -4.60366219e-01,\n       -3.33854817e-02, -2.62010276e-01, -8.72115418e-03,  8.83304048e-03,\n       -4.65513766e-02,  1.46909311e-01,  2.10919499e-01, -1.32199913e-01,\n        2.39372432e-01, -7.42641166e-02,  3.68681774e-02,  2.21318483e-01,\n        2.43092597e-01, -9.27425325e-02, -1.02910049e-01, -2.89757282e-01,\n        3.46549362e-01, -9.94792730e-02,  5.84498271e-02,  6.31556958e-02,\n        7.39775077e-02, -2.33837754e-01, -2.10841149e-01, -2.69284695e-01,\n       -2.05756158e-01,  1.61628395e-01,  1.93372875e-01,  8.46281052e-02,\n        4.28000480e-01, -1.92886919e-01, -9.92264878e-03, -1.14139117e-01,\n       -2.37184372e-02,  3.50787550e-01,  3.70128334e-01,  8.57740492e-02,\n       -1.98146142e-02,  9.72144753e-02, -1.94626991e-02,  7.06190616e-03,\n       -3.10841613e-02, -1.84375584e-01,  2.92848498e-01,  2.97086269e-01,\n       -6.02248609e-02,  1.94523528e-01, -2.87757814e-01,  1.64402667e-02,\n        1.58399105e-01, -2.25561522e-02, -1.09473839e-01,  1.30895957e-01,\n       -2.41885722e-01, -3.41953278e-01,  4.83010747e-02,  8.72804970e-02,\n       -4.98866528e-01, -3.42946351e-01,  7.69382566e-02,  1.37017548e-01,\n        2.58874208e-01,  1.88293844e-01, -1.07000470e-01,  2.99311459e-01,\n       -1.25506923e-01, -2.13982403e-01, -5.48298955e-02,  1.51363388e-02,\n       -1.06285043e-01, -3.01964402e-01, -5.75461052e-02, -5.16939759e-02,\n       -1.00152865e-01,  4.08763289e-01,  1.46928638e-01, -5.10251164e-01,\n        1.30557194e-01, -6.13676459e-02, -1.44916117e-01, -2.52891809e-01,\n       -2.26396710e-01,  2.88019963e-02, -1.12700360e-02, -2.76035398e-01,\n       -9.63674486e-02, -1.38857991e-01,  5.70755638e-02,  3.30633342e-01,\n        2.10687876e-01,  6.72695786e-02,  4.32025582e-01, -2.76977979e-02],\n      dtype=float32)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True,\n",
    "                                  )\n",
    "model.eval()\n",
    "\n",
    "def encode_sentence(sentence):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  # Construct attention masks.\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(encoded_dict['input_ids'], encoded_dict['attention_mask'])\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    token_vecs_cat = torch.stack(hidden_states[-4:], dim=0)\n",
    "    token_vecs_cat = torch.mean(token_vecs_cat, 0)\n",
    "    sentence_embedding = torch.mean(token_vecs_cat, 1)\n",
    "\n",
    "    return sentence_embedding[0].numpy()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # apostrophe ' is not rendered properly so replacing special character with apostrophe\n",
    "    text = text.replace(\"\\x92\", \"'\")\n",
    "    return encode_sentence(text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_and_plot_mfccs(filepath, save_plot=True):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(filepath)\n",
    "    # Compute the MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # You can adjust n_mfcc as needed\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'MFCC of {filepath}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save or show the plot\n",
    "    if save_plot:\n",
    "        plt.savefig(f'{filepath}_mfcc.png')\n",
    "        plt.show()\n",
    "\n",
    "        plt.close()  # Close the plot to free memory\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "def create_spectrogram(filepath):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(filepath)\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel', fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Mel-frequency spectrogram of {filepath}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    audio_length = len(audio)\n",
    "    window_size_samples = int(round(window_size * sample_rate / 1e3))\n",
    "    step_size_samples = int(round(step_size * sample_rate / 1e3))\n",
    "\n",
    "    # Adjust nperseg and noverlap for very short audio\n",
    "    nperseg = min(window_size_samples, audio_length // 3)\n",
    "    noverlap = min(step_size_samples, nperseg // 2, audio_length // 4)\n",
    "\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)\n",
    "\n",
    "def audio2spectrogram_and_save(filepath):\n",
    "    samplerate, test_sound = wavfile.read(filepath, mmap=True)\n",
    "    if test_sound.ndim > 1:\n",
    "        test_sound = test_sound.mean(axis=1)\n",
    "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "    plt.figure(figsize=(10, 4))  # Adjust size as needed\n",
    "    plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "    plt.title(f'Spectrogram of {filepath}')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    # Save the plot instead of showing it\n",
    "    if not os.path.exists(\"./spectrogram_dir\"):\n",
    "        os.makedirs(\"./spectrogram_dir\")\n",
    "    plt.savefig(os.path.join(\"./spectrogram_dir\", f'{filepath}_spectrogram.png'))\n",
    "    plt.show()\n",
    "    plt.close()  # Close the plot to free memory\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "\n",
    "def audio2wave(filepath):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    samplerate, test_sound  = wavfile.read(filepath,mmap=True)\n",
    "    plt.plot(test_sound)\n",
    "\n",
    "\n",
    "# Example usage11\n",
    "filepaths = [f'/content/dia0_utt{i}.wav' for i in range(10)]\n",
    "for filepath in filepaths:\n",
    "    spectrogram = audio2spectrogram_and_save(filepath)\n",
    "    print(f'{filepath}: Spectrogram shape: {spectrogram.shape}')\n",
    "\n",
    "def preprocess_audio(audio):\n",
    "\n",
    "    return audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class AudioEmotionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioEmotionModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class AudioTextEmotionModel(nn.Module):\n",
    "    def __init__(self, audio_model, text_model, num_classes):\n",
    "        super(AudioTextEmotionModel, self).__init__()\n",
    "        self.audio_model = audio_model\n",
    "        self.text_model = text_model\n",
    "        self.fc = nn.Linear(2 * audio_model.conv4.out_channels, num_classes)\n",
    "\n",
    "    def forward(self, audio, text):\n",
    "        audio_out = self.audio_model(audio)\n",
    "        text_out = self.text_model(text)\n",
    "        combined = torch.cat([audio_out, text_out], dim=1)\n",
    "        return self.fc(combined)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss Function and Optimizer\n",
    "One final step before we can simply call `model.fit`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init class1\n",
      "init class2\n",
      "False\n",
      "True\n",
      "True\n",
      "5\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for text, audio, label in dataloader:\n",
    "            audio = audio.to(device)\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(audio, text)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
